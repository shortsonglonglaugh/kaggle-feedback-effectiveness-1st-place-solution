{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4013f9-46e4-4aff-a019-3331c68e0c02",
   "metadata": {},
   "source": [
    "### Prepare folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e38d9-33f0-49dd-a2f7-de2ba550ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4899aa-a512-4a0f-a508-b8237bf66593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(\n",
    "    list(\n",
    "        StratifiedGroupKFold(n_splits=5).split(\n",
    "            np.arange(len(df)), df.discourse_effectiveness, groups=df[\"essay_id\"]\n",
    "        )\n",
    "    )\n",
    "):\n",
    "    df.loc[val_idx, \"fold\"] = fold\n",
    "df[\"fold\"] = df[\"fold\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ae835c-1256-4239-b9ee-a31e9599d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.fold, df.discourse_effectiveness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b2b5e-0165-4325-938d-afb68dc71715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../data/train_folded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334632fb-d2ee-4595-92f1-0e12a1bc6cc1",
   "metadata": {},
   "source": [
    "### Prepare previous competition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f27e98-f6bd-4cc3-8961-8c7e9966b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/feedback_2021/train.csv\")\n",
    "\n",
    "df.columns = ['essay_id', 'discourse_id', 'discourse_start', 'discourse_end',\n",
    "       'discourse_text', 'discourse_type', 'discourse_type_num',\n",
    "       'predictionstring']\n",
    "new = pd.read_csv(\"../data/train_folded.csv\")\n",
    "\n",
    "df = df[~df.essay_id.isin(new.essay_id)].reset_index(drop=True)\n",
    "\n",
    "essay_texts = {}\n",
    "for fname in tqdm(glob(\"../data/feedback_2021/train/*.txt\")):\n",
    "    with open(fname) as f:\n",
    "        lines = f.read()\n",
    "        \n",
    "    essay_texts[fname.split(\"/\")[-1][:-4]] = lines\n",
    "    \n",
    "df[\"essay_text\"] = df.essay_id.map(essay_texts)\n",
    "\n",
    "# df.to_csv(\"../data/old_competition_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af802009-87ed-41f3-83de-3134d9286149",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs = []\n",
    "\n",
    "for name, gr in tqdm(df.groupby(\"essay_id\", sort=False)):\n",
    "    essay_text_start_end = gr.essay_text.values[0]\n",
    "    token_labels = []\n",
    "    token_obs = []\n",
    "    \n",
    "    end_pos = 0\n",
    "    for idx, row in gr.reset_index(drop=True).iterrows():\n",
    "        target_text = row[\"discourse_text\"].strip()\n",
    "\n",
    "        essay_text_start_end = essay_text_start_end[:end_pos] + essay_text_start_end[end_pos:].replace(row[\"discourse_text\"].strip(), target_text, 1)\n",
    "        \n",
    "        start_pos = essay_text_start_end[end_pos:].find(target_text)\n",
    "        if start_pos == -1:\n",
    "            raise ValueError()\n",
    "        start_pos += end_pos\n",
    "        \n",
    "        if idx == 0 and start_pos > 0:\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[:start_pos])\n",
    "        \n",
    "        if start_pos > end_pos and end_pos > 0:\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[end_pos:start_pos])\n",
    "\n",
    "\n",
    "        end_pos = start_pos + len(target_text)\n",
    "        token_labels.append(\"A\" + row[\"discourse_type\"])\n",
    "        token_obs.append(essay_text_start_end[start_pos: end_pos])\n",
    "            \n",
    "        if idx == len(gr) - 1 and end_pos < len(essay_text_start_end):\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[end_pos:])\n",
    "        \n",
    "    all_obs.append((name, token_labels, token_obs))\n",
    "\n",
    "tt = pd.DataFrame(all_obs, columns=[\"essay_id\", \"tokens\", \"essay_text\"])\n",
    "# tt.to_parquet(\"../data/feedback_2021_pretrain.pq\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23556a5d-dbb0-4c72-be83-20900facf1a9",
   "metadata": {},
   "source": [
    "### Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc1276-f60c-435d-b153-c6e783097a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/train_folded.csv\")\n",
    "df.loc[df.discourse_id == \"56744a66949a\", \"discourse_text\"] = \"This whole thing is point less how they have us in here for two days im missing my education. We could have finished this in one day and had the rest of the week to get back on the track of learning. I've missed both days of weight lifting, algebra, and my world history that i do not want to fail again! If their are any people actually gonna sit down and take the time to read this then\\n\\nDO NOT DO THIS NEXT YEAR\\n\\n.\\n\\nThey are giving us cold lunches. ham and cheese and an apple, I am 16 years old and my body needs proper food. I wouldnt be complaining if they served actual breakfast. but because of Michelle Obama and her healthy diet rule they surve us 1 poptart in the moring. How does the school board expect us to last from 7:05-12:15 on a pop tart? then expect us to get A's, we are more focused on lunch than anything else. I am about done so if you have the time to read this even though this does not count. Bring PROPER_NAME a big Mac from mc donalds, SCHOOL_NAME, (idk area code but its in LOCATION_NAME)       \\xa0    \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aace2ad-65dc-4d63-9c7f-c34860ab5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs = []\n",
    "\n",
    "for name, gr in tqdm(df.groupby(\"essay_id\", sort=False)):\n",
    "    essay_text_start_end = gr.essay_text.values[0]\n",
    "    token_labels = []\n",
    "    token_obs = []\n",
    "    \n",
    "    end_pos = 0\n",
    "    for idx, row in gr.reset_index(drop=True).iterrows():\n",
    "        target_text = row[\"discourse_type\"] + \" \" + row[\"discourse_text\"].strip()\n",
    "        essay_text_start_end = essay_text_start_end[:end_pos] + essay_text_start_end[end_pos:].replace(row[\"discourse_text\"].strip(), target_text, 1)\n",
    "        \n",
    "        start_pos = essay_text_start_end[end_pos:].find(target_text)\n",
    "        if start_pos == -1:\n",
    "            raise ValueError()\n",
    "        start_pos += end_pos\n",
    "        \n",
    "        if idx == 0 and start_pos > 0:\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[:start_pos])\n",
    "        \n",
    "        if start_pos > end_pos and end_pos > 0:\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[end_pos:start_pos])\n",
    "\n",
    "        end_pos = start_pos + len(target_text)\n",
    "        token_labels.append(row[\"discourse_effectiveness\"])\n",
    "        token_obs.append(essay_text_start_end[start_pos: end_pos])\n",
    "            \n",
    "        if idx == len(gr) - 1 and end_pos < len(essay_text_start_end):\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[end_pos:])\n",
    "    all_obs.append((name, token_labels, token_obs, row[\"fold\"]))\n",
    "    \n",
    "tt = pd.DataFrame(all_obs, columns=[\"essay_id\", \"tokens\", \"essay_text\", \"fold\"])\n",
    "# tt.to_parquet(\"../data/feedback_text_token_classification_v5.pq\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28cbb0c-5ce2-415c-ab9d-d9e2729fb24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs = []\n",
    "\n",
    "for name, gr in tqdm(df.groupby(\"essay_id\", sort=False)):\n",
    "    essay_text_start_end = gr.essay_text.values[0]\n",
    "    token_labels = []\n",
    "    token_obs = []\n",
    "    \n",
    "    end_pos = 0\n",
    "    token_obs.append(\" \".join(gr.discourse_type.to_list()))\n",
    "    token_labels.append(\"O\")\n",
    "    for idx, row in gr.reset_index(drop=True).iterrows():\n",
    "        target_text = row[\"discourse_type\"] + \" \" + row[\"discourse_text\"].strip()\n",
    "        essay_text_start_end = essay_text_start_end[:end_pos] + essay_text_start_end[end_pos:].replace(row[\"discourse_text\"].strip(), target_text, 1)\n",
    "        \n",
    "        start_pos = essay_text_start_end[end_pos:].find(target_text)\n",
    "        if start_pos == -1:\n",
    "            raise ValueError()\n",
    "        start_pos += end_pos\n",
    "        \n",
    "        if idx == 0 and start_pos > 0:\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[:start_pos])\n",
    "        \n",
    "        if start_pos > end_pos and end_pos > 0:\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[end_pos:start_pos])\n",
    "\n",
    "        end_pos = start_pos + len(target_text)\n",
    "        token_labels.append(row[\"discourse_effectiveness\"])\n",
    "        token_obs.append(essay_text_start_end[start_pos: end_pos])\n",
    "            \n",
    "        if idx == len(gr) - 1 and end_pos < len(essay_text_start_end):\n",
    "            token_labels.append(\"O\")\n",
    "            token_obs.append(essay_text_start_end[end_pos:])\n",
    "    all_obs.append((name, token_labels, token_obs, row[\"fold\"]))\n",
    "    \n",
    "tt = pd.DataFrame(all_obs, columns=[\"essay_id\", \"tokens\", \"essay_text\", \"fold\"])\n",
    "# tt.to_parquet(\"../data/feedback_text_token_classification_types.pq\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1aaae-2cbf-44e1-a795-5cfc5fe08e02",
   "metadata": {},
   "source": [
    "### Prepare pseudo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21966f5b-ee73-41fc-9c7d-07904f77db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "labels = pd.read_csv(\"../data/pseudo_75_ff_raw.csv\")\n",
    "# labels = pd.read_csv(\"../data/pseudo_104_ff_raw.csv\")\n",
    "# labels = pd.read_csv(\"../data/pseudo_140_ff_raw.csv\")\n",
    "df = pd.read_csv(\"../data/old_competition_data.csv\")\n",
    "df = df.merge(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5935399-04a8-46e5-87ec-0bb4e38830a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs = []\n",
    "\n",
    "for name, gr in tqdm(df.groupby(\"essay_id\", sort=False)):\n",
    "    essay_text_start_end = gr.essay_text.values[0]\n",
    "    token_labels = []\n",
    "    token_obs = []\n",
    "    end_pos = 0\n",
    "    \n",
    "    # Pseudo with types in the beginning (pseudo 104 and 140)\n",
    "    # token_obs.append(\" \".join(gr.discourse_type.to_list()))\n",
    "    # token_labels.append([-1, -1, -1])\n",
    "    \n",
    "    for idx, row in gr.reset_index(drop=True).iterrows():\n",
    "        target_text = row[\"discourse_type\"] + \" \" + row[\"discourse_text\"].strip()\n",
    "\n",
    "        essay_text_start_end = essay_text_start_end[:end_pos] + essay_text_start_end[end_pos:].replace(row[\"discourse_text\"].strip(), target_text, 1)\n",
    "        \n",
    "        start_pos = essay_text_start_end[end_pos:].find(target_text)\n",
    "        if start_pos == -1:\n",
    "            raise ValueError()\n",
    "        start_pos += end_pos\n",
    "        \n",
    "        if idx == 0 and start_pos > 0:\n",
    "            # Soft_Labels\n",
    "            token_labels.append([-1, -1, -1])\n",
    "            token_obs.append(essay_text_start_end[:start_pos])\n",
    "        \n",
    "        if start_pos > end_pos and end_pos > 0:\n",
    "            # Soft_Labels\n",
    "            token_labels.append([-1, -1, -1])\n",
    "            token_obs.append(essay_text_start_end[end_pos:start_pos])\n",
    "\n",
    "\n",
    "        end_pos = start_pos + len(target_text)\n",
    "        # Soft_Labels\n",
    "        token_labels.append([row[\"Adequate\"], row[\"Effective\"], row[\"Ineffective\"]])\n",
    "        token_obs.append(essay_text_start_end[start_pos: end_pos])\n",
    "            \n",
    "        if idx == len(gr) - 1 and end_pos < len(essay_text_start_end):\n",
    "            # Soft_Labels\n",
    "            token_labels.append([-1, -1, -1])\n",
    "            token_obs.append(essay_text_start_end[end_pos:])\n",
    "            \n",
    "    all_obs.append((name, token_labels, token_obs))\n",
    "\n",
    "tt = pd.DataFrame(all_obs, columns=[\"essay_id\", \"tokens\", \"essay_text\"])\n",
    "\n",
    "# tt.to_parquet(\"../data/pseudo_75_ff.pq\", index=False)\n",
    "# tt.to_parquet(\"../data/pseudo_104_ff.pq\", index=False)\n",
    "# tt.to_parquet(\"../data/pseudo_140_ff.pq\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dda8e5-6f32-4f3b-ba21-27368540d8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

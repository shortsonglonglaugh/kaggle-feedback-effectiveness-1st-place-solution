{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = pd.read_csv(\"../../data/oof_151_after_scaling_ind_models.csv\")\n",
    "tt = pd.read_csv(\"../../data/train_folded.csv\")\n",
    "oof = tt[['discourse_id', \"fold\", \"discourse_text\", \"essay_text\"]].merge(oof)\n",
    "mapping = {\"Adequate\": 0, \"Effective\": 1, \"Ineffective\": 2}\n",
    "oof[\"label\"] = oof.discourse_effectiveness.map(mapping)\n",
    "df = oof.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x(values):\n",
    "    range = 1\n",
    "    return np.histogram(np.clip(values, 0.001, 0.999*range), bins=3, density=True, range=(0,range))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = []\n",
    "\n",
    "gb = df.groupby('essay_id', sort=False)\n",
    "for name, group in tqdm(gb):\n",
    "    group[\"n_types\"] = group.discourse_type.nunique()\n",
    "\n",
    "    for class_name in [\"Adequate\", \"Effective\", \"Ineffective\"]:\n",
    "        if class_name in [\"Adequate\", \"Effective\"]:\n",
    "            continue\n",
    "\n",
    "        for idx, val in enumerate(gen_x(group[class_name].values)):\n",
    "            group[f\"{class_name}_bin_{idx}\"] = val \n",
    "\n",
    "        group[f\"mean_{class_name}\"] = group[class_name].mean()\n",
    "        group[f\"max_{class_name}\"] = group[class_name].max()\n",
    "\n",
    "    for class_name in [f\"Ineffective_{i}\" for i in range(15)]:\n",
    "        group[f\"mean_{class_name}\"] = group[class_name].mean()  \n",
    "\n",
    "    for class_name in [f\"Effective_{i}\" for i in range(15)]:\n",
    "        group[f\"mean_{class_name}\"] = group[class_name].mean()  \n",
    "\n",
    "    all_groups.append(group)\n",
    "\n",
    "df = pd.concat(all_groups).reset_index(drop=True)\n",
    "\n",
    "df[\"paragraph_cnt\"] = df.essay_text.map(lambda x: len(x.split(\"\\n\\n\")))\n",
    "\n",
    "disc_types_mapping = {'Lead': 0,\n",
    "'Position': 1,\n",
    "'Claim': 2,\n",
    "'Evidence': 3,\n",
    "'Counterclaim': 4,\n",
    "'Rebuttal': 5,\n",
    "'Concluding Statement': 6}\n",
    "\n",
    "df[\"discourse_type\"] = df[\"discourse_type\"].map(disc_types_mapping)\n",
    "\n",
    "for i in range(15):\n",
    "    df = df.drop([f'Adequate_{i}'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b458e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/train_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ef1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple\n",
    "import datetime\n",
    "import pytz\n",
    "import json\n",
    "\n",
    "\n",
    "class TabularModel:\n",
    "    def read_data(self, config: dict) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        train_raw = pd.read_csv(config[\"train_path\"])\n",
    "        return train_raw\n",
    "\n",
    "    def prepare_features(\n",
    "        self,\n",
    "        train_raw: pd.DataFrame,\n",
    "        train_targets: np.array,\n",
    "        train_folds: np.array,\n",
    "        config: dict,\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "        df = train_raw.copy()\n",
    "        return (\n",
    "            df,\n",
    "            config,\n",
    "        )\n",
    "\n",
    "    def metric(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        raise NotImplementedError(\"Method has not been implemented\")\n",
    "\n",
    "    def fit_predict(\n",
    "        self, config, X_train, y_train, X_valid, y_valid\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        raise NotImplementedError(\"Method has not been implemented\")\n",
    "\n",
    "    def preprocess_target(self, config: dict, target: np.array) -> np.array:\n",
    "        return target\n",
    "\n",
    "    def postprocess_predictions(self, config: dict, preds: np.ndarray) -> np.ndarray:\n",
    "        return preds\n",
    "\n",
    "    def set_seed(self, seed: int) -> None:\n",
    "        random.seed(seed)\n",
    "        os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def run_cv(self, config: dict, fold=None, save_results: bool = True) -> float:\n",
    "        timetag = (\n",
    "            pytz.utc.localize(datetime.datetime.utcnow())\n",
    "            .astimezone(pytz.timezone(\"Europe/Vienna\"))\n",
    "            .strftime(\"%m%d_%H%M%S\")\n",
    "        )\n",
    "\n",
    "        self.set_seed(config[\"seed\"])\n",
    "        train_raw = self.read_data(config)\n",
    "\n",
    "        if (fold is not None) and (fold not in train_raw[config[\"fold_column\"]]):\n",
    "            print(f\"Fold {fold} not found in the data\")\n",
    "            return None\n",
    "\n",
    "\n",
    "        train, config = self.prepare_features(\n",
    "            train_raw,\n",
    "            None,\n",
    "            None,\n",
    "            config,\n",
    "        )\n",
    "        train_targets = train[config[\"target_column\"]].copy()\n",
    "        train_folds = train[config[\"fold_column\"]].copy()\n",
    "        to_out = train.copy()\n",
    "        train = train.drop([config[\"fold_column\"], config[\"target_column\"], \"discourse_id\"], axis=1)\n",
    "        \n",
    "        features = list(train.columns)\n",
    "        train = train[pd.notnull(train_targets)]\n",
    "\n",
    "        validation_oof = np.zeros((len(train), config[\"n_classes\"]))\n",
    "        results = {}\n",
    "\n",
    "        if fold is None:\n",
    "            output_folder = (\n",
    "                f\"{config['output_folder']}/{type(self).__name__}/cv/{timetag}\"\n",
    "            )\n",
    "        else:\n",
    "            output_folder = (\n",
    "                f\"{config['output_folder']}/{type(self).__name__}/fold_{fold}/{timetag}\"\n",
    "            )\n",
    "\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        for _fold in np.sort(train_folds.unique()):\n",
    "            if (fold is not None) and (_fold != fold):\n",
    "                continue\n",
    "            if config[\"print_progress\"]:\n",
    "                print(\"*\" * 20 + f\"FOLD: {_fold}\" + \"*\" * 20)\n",
    "\n",
    "            X_train = train[train_folds != _fold].copy()\n",
    "            y_train = train_targets[train_folds != _fold]\n",
    "            X_valid = train[train_folds == _fold].copy()\n",
    "            y_valid = train_targets[train_folds == _fold]\n",
    "\n",
    "            gbm, pred_valid = self.fit_predict(\n",
    "                config,\n",
    "                X_train[features],\n",
    "                self.preprocess_target(config, y_train),\n",
    "                X_valid[features],\n",
    "                self.preprocess_target(config, y_valid),\n",
    "            )\n",
    "            \n",
    "            gbm.save_model(f\"{output_folder}/model_fold_{_fold}.txt\", num_iteration=config[\"model_params\"][\"n_estimators\"])\n",
    "            pred_valid = self.postprocess_predictions(config, pred_valid)\n",
    "\n",
    "            # Validation predictions\n",
    "            if config[\"n_classes\"] == 1:\n",
    "                pred_valid = pred_valid.reshape(-1, 1)\n",
    "            validation_oof[train_folds == _fold] = pred_valid\n",
    "            \n",
    "            fold_metric = self.metric(y_valid, pred_valid)\n",
    "            results[str(_fold)] = fold_metric\n",
    "            if config[\"print_progress\"]:\n",
    "                print(f\"Metric for fold {_fold}: {fold_metric:.5f}\")\n",
    "\n",
    "        if fold is None:\n",
    "            oof_metric = self.metric(train_targets, validation_oof, train_folds)\n",
    "            if config[\"print_progress\"]:\n",
    "                print(f\"OOF metric: {oof_metric:.5f}\")\n",
    "            results[\"oof\"] = oof_metric\n",
    "            output_metric = oof_metric\n",
    "        else:\n",
    "            output_metric = fold_metric\n",
    "            \n",
    "        results[\"features\"] = features\n",
    "\n",
    "        if save_results:\n",
    "            np.save(\n",
    "                f\"{output_folder}/validation_oof_preds.npy\",\n",
    "                np.array(validation_oof),\n",
    "            )\n",
    "            with open(f\"{output_folder}/config.json\", \"w\") as fp:\n",
    "                json.dump(config, fp, indent=4)\n",
    "            with open(f\"{output_folder}/results.json\", \"w\") as fp:\n",
    "                json.dump(results, fp, indent=4)\n",
    "            print(f\"Results saved to {output_folder}\")\n",
    "            \n",
    "\n",
    "        return output_metric, output_folder, to_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe227fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "class LGBM(TabularModel):\n",
    "    def fit_predict(self, config, X_train, y_train, X_valid, y_valid):\n",
    "        train_data = lightgbm.Dataset(X_train, label=y_train, params={\"verbose\": -1})\n",
    "        if (X_valid is not None) and (y_valid is not None):\n",
    "            valid_data = lightgbm.Dataset(\n",
    "                X_valid, label=y_valid, params={\"verbose\": -1}\n",
    "            )\n",
    "        else:\n",
    "            valid_data = None\n",
    "\n",
    "        if (valid_data is None) or (config[\"model_params\"].get(\"verbose_eval\", 1) < 0):\n",
    "            gbm = lightgbm.train(\n",
    "                {\n",
    "                    k: v\n",
    "                    for k, v in config[\"model_params\"].items()\n",
    "                    if k not in [\"verbose_eval\", \"n_estimators\"]\n",
    "                },\n",
    "                train_data,\n",
    "                num_boost_round=config[\"model_params\"].get(\"n_estimators\", 1000),\n",
    "            )\n",
    "            print(X_train.head(), config[\"model_params\"].get(\"n_estimators\", 1000))\n",
    "        else:\n",
    "            gbm = lightgbm.train(\n",
    "                {\n",
    "                    k: v\n",
    "                    for k, v in config[\"model_params\"].items()\n",
    "                    if k not in [\"verbose_eval\", \"n_estimators\"]\n",
    "                },\n",
    "                train_data,\n",
    "                num_boost_round=config[\"model_params\"].get(\"n_estimators\", 1000),\n",
    "                valid_sets=valid_data,\n",
    "                verbose_eval=config[\"model_params\"].get(\"verbose_eval\", \"warn\"),\n",
    "            )\n",
    "\n",
    "        if X_valid is None:\n",
    "            valid_pred = None\n",
    "        else:\n",
    "            valid_pred = gbm.predict(X_valid)\n",
    "\n",
    "        return gbm, valid_pred\n",
    "    \n",
    "    def metric(self, y_true, y_pred, train_folds=None) -> float:\n",
    "        print(metrics.log_loss(y_true, y_pred))\n",
    "        \n",
    "        y = np.zeros_like(y_pred)\n",
    "\n",
    "        for ii, jj in enumerate([x for x in y_true]):\n",
    "            y[ii,jj] = 1\n",
    "        \n",
    "        pp2 = y_pred.copy()\n",
    "        for _ in range(100):\n",
    "            pp2 = pp2 * (y.mean(axis=0) / pp2.mean(axis=0))\n",
    "            pp2 = pp2 / pp2.sum(axis=1, keepdims=True)\n",
    "            \n",
    "        if train_folds is not None:\n",
    "            for f in range(5):\n",
    "                print(f\"FOLD {f}: {metrics.log_loss(y_true[train_folds == f], pp2[train_folds == f])}\")\n",
    "        \n",
    "        return metrics.log_loss(y_true, pp2)\n",
    "\n",
    "    def prepare_features(\n",
    "        self,\n",
    "        train_raw: pd.DataFrame,\n",
    "        train_targets: np.array,\n",
    "        train_folds: np.array,\n",
    "        config: dict,\n",
    "    ):\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        df = train_raw.copy()\n",
    "        \n",
    "        all_groups = []               \n",
    "           \n",
    "        df = df.drop([\"discourse_text\", \"essay_text\", \"essay_id\", \"discourse_effectiveness\"], axis=1)\n",
    "        print(df.columns)\n",
    "        return (\n",
    "            df,\n",
    "            config,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db42f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    train_path=\"../../data/train_lgb.csv\",\n",
    "    fold_column=\"fold\",\n",
    "    target_column=\"label\",\n",
    "    n_classes=3,\n",
    "    regression=False,\n",
    "    seed=1337,\n",
    "    output_folder=\"lightgbm/results\",\n",
    "    print_progress=True,\n",
    "    data_params={},\n",
    "    model_params={\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"num_classes\": 3,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"n_estimators\": 200,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"num_leaves\": 10,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"seed\": 1337,\n",
    "        \"verbose\": -1,\n",
    "        \"num_threads\": 40,\n",
    "        \"early_stopping_round\": -1,\n",
    "        \"verbose_eval\": 50,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBM()\n",
    "output_metric, output_folder, new_df = model.run_cv(config, fold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596393e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

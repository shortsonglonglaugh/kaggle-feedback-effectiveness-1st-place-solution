{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3247ba-2ce2-49a5-9340-c8093fd4aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c29bc7-0d5c-41c6-80df-5a1b40b18bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4\n",
    "]\n",
    "\n",
    "orig = pd.read_csv(\"../data/train_folded.csv\").set_index(\"discourse_id\")\n",
    "orig = orig[orig.fold.isin(folds)]\n",
    "\n",
    "exps = [    \n",
    "    \"lgb_models/lgb_v0\",\n",
    "    \"yauhen/olivine-spaniel\",\n",
    "    \"yauhen/saffron-rook\",\n",
    "    \"yauhen/meteoric-bettong\",\n",
    "    \"yauhen/big-ocelot\",\n",
    "    \"yauhen/shrewd-rook-3ep\",\n",
    "    \"yauhen/conscious-uakari\",\n",
    "    \"valiant-degu\", \n",
    "    \"axiomatic-vulture\",\n",
    "    \"smart-bumblebee\",\n",
    "    \"awesome-rose\",\n",
    "    \"honest-apple\",\n",
    "    \"funky-funk\",\n",
    "    \"lame-flame\",\n",
    "    \"pastel-frog\",\n",
    "]\n",
    "\n",
    "preds = []\n",
    "label_cols = [\"Adequate\", \"Effective\", \"Ineffective\"]\n",
    "for exp_name in exps:\n",
    "    \n",
    "    print(exp_name)\n",
    "    \n",
    "    pps = []\n",
    "    if \"yauhen\" in exp_name:\n",
    "        for seed in range(1,4):\n",
    "            v = pd.read_csv(f\"../data/yauhen/{exp_name.split('/')[-1]}_seed_{seed}.csv\")\n",
    "            v = v.set_index(\"discourse_id\")\n",
    "            v = v.loc[orig.index]\n",
    "\n",
    "            pps.append(v[label_cols].values)\n",
    "    elif \"lgb_models\" in exp_name:\n",
    "        for seed in range(1):\n",
    "            vs = []\n",
    "            for fold in folds:\n",
    "                v = pd.read_csv(f\"../data/lgb_models/{exp_name.split('/')[-1]}/fold{fold}/validation_predictions_seed{seed}.csv\")\n",
    "                vs.append(v)\n",
    "                \n",
    "            v = pd.concat(vs)\n",
    "            v = v.set_index(\"discourse_id\")\n",
    "            v = v.loc[orig.index]\n",
    "            \n",
    "            pps.append(v[label_cols].values)\n",
    "    else:\n",
    "        exp_names = []\n",
    "        for j in range(3):\n",
    "            if j == 0:\n",
    "                exp_names.append(exp_name)\n",
    "            else:\n",
    "                exp_names.append(f\"{exp_name}.{j}\")\n",
    "\n",
    "        for exp_name in exp_names[:3]:\n",
    "            vs = []\n",
    "            for fold in folds:\n",
    "                v = pd.read_csv(f\"../data/philipp/{exp_name}/fold{fold}/validation_predictions.csv\")\n",
    "\n",
    "                p = v[[f\"pred_discourse_effectiveness_{c}\" for c in label_cols]].values\n",
    "\n",
    "                v[\"Adequate\"] = p[:, 0]\n",
    "                v[\"Effective\"] = p[:, 1]\n",
    "                v[\"Ineffective\"] = p[:, 2]\n",
    "\n",
    "                vs.append(v)\n",
    "\n",
    "            v = pd.concat(vs)\n",
    "            v = v.set_index(\"discourse_id\")\n",
    "            v = v.loc[orig.index]\n",
    "\n",
    "            pps.append(v[label_cols].values)\n",
    "\n",
    "    pps = np.mean(pps, axis=0)\n",
    "\n",
    "    preds.append(pps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec6ac0-e7c2-40fc-be54-bf2e6934c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros_like(preds[0])\n",
    "for ii, jj in enumerate([label_cols.index(x) for x in orig[\"discourse_effectiveness\"].values]):\n",
    "    y[ii,jj] = 1\n",
    "ps = np.array(preds).copy()\n",
    "\n",
    "def scale_probs(pp_single):\n",
    "    pp = pp_single.copy()\n",
    "\n",
    "    for _ in range(100):\n",
    "        pp = pp * (y.mean(axis=0).reshape(1,3) / pp.mean(axis=0))\n",
    "        pp = pp / pp.sum(axis=1, keepdims=True)\n",
    "        \n",
    "    return pp\n",
    "\n",
    "for i,ppp in enumerate(ps):\n",
    "    preds[i] = scale_probs(ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb350455-be35-4544-9501-88da77b230d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_tune(weights, preds):\n",
    "    pp = np.average(preds, axis=0, weights=weights)\n",
    "    \n",
    "    eps = 0.0001\n",
    "    pp = pp.clip(eps, 1 - eps)\n",
    "    pp = pp / pp.sum(axis=1, keepdims=True)\n",
    "\n",
    "        \n",
    "    pp2 = pp.copy()\n",
    "    for _ in range(10):\n",
    "        pp2 = pp2 * (y.mean(axis=0) / pp2.mean(axis=0))\n",
    "        pp2 = pp2 / pp2.sum(axis=1, keepdims=True)\n",
    "    pp = pp2\n",
    "\n",
    "    err = log_loss(y, pp)\n",
    "    return err\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "weights_init = [1] * len(preds)\n",
    "\n",
    "res = minimize(weights_tune, weights_init, args=(preds), method='Nelder-Mead', tol=1e-6)\n",
    "print(\"Optimized weights: \", res.x)\n",
    "weights = res.x\n",
    "\n",
    "pp = np.average(preds, axis=0, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d895d3-ab5c-4ffa-af87-4c94045c9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.0001\n",
    "pp = pp.clip(eps, 1 - eps)\n",
    "pp = pp / pp.sum(axis=1, keepdims=True)\n",
    "\n",
    "pp = scale_probs(pp)\n",
    "\n",
    "y = np.zeros_like(pp)\n",
    "\n",
    "for ii, jj in enumerate([label_cols.index(x) for x in orig[\"discourse_effectiveness\"].values]):\n",
    "    y[ii,jj] = 1\n",
    "\n",
    "print(log_loss(y, pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7574a4-ccff-457f-bdc7-b84f63ba6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = v[[\"essay_id\", \"discourse_type\", \"discourse_effectiveness\", \"Adequate\", \"Effective\", \"Ineffective\"]].copy()\n",
    "df[\"Adequate\"] = pp[:,0]\n",
    "df[\"Effective\"] = pp[:,1]\n",
    "df[\"Ineffective\"] = pp[:,2]\n",
    "\n",
    "df.to_csv(\"../data/oof_151_after_scaling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003066a5-b066-4bf8-ae31-1a8eedd9f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id, model_pred in enumerate(preds):\n",
    "    df[f\"Adequate_{model_id}\"] = model_pred[:,0]\n",
    "    df[f\"Effective_{model_id}\"] = model_pred[:,1]\n",
    "    df[f\"Ineffective_{model_id}\"] = model_pred[:,2]\n",
    "\n",
    "df.to_csv(\"../data/oof_151_after_scaling_ind_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23b3f9-25cd-483d-a323-65d454394b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/first_lvl_ensemble.npy\", pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5519b-b8d2-4e0f-9551-e0b76451be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/first_lvl_ensemble.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5ee89-711c-424b-bbaa-43a061ccd2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

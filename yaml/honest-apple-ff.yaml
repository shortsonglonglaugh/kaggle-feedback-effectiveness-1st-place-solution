dataset_class: feedback_essay_ds
model_class: feedback_essay_model
architecture:
    aux_type: true
    backbone: microsoft/deberta-v3-large
    custom_intermediate_dropout: false
    dropout: 0
    gradient_checkpointing: false
    intermediate_dropout: 0.1
    pool: All [CLS] token
    pretrained_weights: output/pseudo-pretrain-104-seedblend-aux-v10-ff/checkpoint.pth
    use_sep: false
    use_type: false
    wide_dropout: 0.1
dataset:
    add_group_types: true
    fold: 0
    group_discourse: true
    label_columns:
    - discourse_effectiveness_Adequate
    - discourse_effectiveness_Effective
    - discourse_effectiveness_Ineffective
    separator: ''
    text_column:
    - essay_text
    train_dataframe: data/train_folded.csv
environment:
    mixed_precision: true
    number_of_workers: 4
    seed: -1
experiment_name: honest-apple-ff
tokenizer:
    add_newline_token: true
    lowercase: false
    max_length: 2048
training:
    aux_loss_function: CrossEntropy
    batch_size: 1
    differential_learning_rate: 0.0001
    differential_learning_rate_layers:
    - head
    drop_last_batch: true
    epoch_subsample: 0
    epochs: 6
    grad_accumulation: 9
    gradient_clip: 0
    learning_rate: 1.0e-05
    loss_function: FocalLoss
    mixup_concentration: 1
    mixup_probability: 0
    optimizer: AdamW
    schedule: Cosine
    train_validation_data: true
    warmup_epochs: 0
    weight_decay: 0

dataset_class: feedback_dataset
model_class: feedback_model
architecture:
    add_wide_dropout: false
    backbone: microsoft/deberta-large
    dropout: 0.1
    gradient_checkpointing: true
    pretrained_weights: output/pretrain-2021/checkpoint.pth
dataset:
    fold: -1
    label_columns: tokens
    num_classes: 3
    text_column: essay_text
    train_dataframe: data/feedback_text_token_classification_v5.pq
environment:
    mixed_precision: true
    number_of_workers: 4
    seed: -1
experiment_name: shrewd-rook-3ep-ff
tokenizer:
    lowercase: false
    max_length: 2048
training:
    add_types: false
    batch_size: 4
    differential_learning_rate: 1.0e-05
    differential_learning_rate_layers: []
    drop_last_batch: true
    epochs: 3
    grad_accumulation: 1
    gradient_clip: 5
    is_pseudo: false
    learning_rate: 2.0e-05
    loss_function: CrossEntropy
    num_eval_per_epoch: 1
    optimizer: AdamW
    schedule: Linear
    warmup_epochs: 1.5
    weight_decay: 0.001
